{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../data/Final Categorization Data.csv\"\n",
    "df = pd.read_csv(filepath)\n",
    "\n",
    "#drop extra binned columns for categorization models\n",
    "df = df.drop(df.iloc[:,82:100], axis = 1)\n",
    "df['Origin Destination New Region'] = df['Origin Province'] + df['New Regions']\n",
    "#one hot encode remaining categorical variables\n",
    "one_hot_columns = [\"Main Transportation Method\", \"Quarter\", \"Main Reason\" ]\n",
    "df2 = pd.get_dummies(df, columns = one_hot_columns)\n",
    "df2 = pd.get_dummies(df2, columns = [\"Origin Destination New Region\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of column names for each feature\n",
    "transport_cols = [col for col in df2.columns if ('Main Transportation Method') in col]\n",
    "quarter_cols = [col for col in df2.columns if 'Quarter' in col]\n",
    "mainreason_cols = [col for col in df2.columns if 'Main Reason' in col]\n",
    "Origin_Destination_New_Region_cols = [col for col in df2.columns if 'Origin Destination New Region' in col]\n",
    "\n",
    "#get dataframe subsets based on list of col names \n",
    "num_features = df2.loc[:,[\"DURATION\", \"GNCQ06A\", \"GNCQ06B\"]]\n",
    "transport = df2.loc[:,transport_cols]\n",
    "quarter = df2.loc[:,quarter_cols]\n",
    "main_reason = df2.loc[:,mainreason_cols]\n",
    "ori_dest_newregion = df2.loc[:,Origin_Destination_New_Region_cols]\n",
    "high_correlation_activities_cols =  df2.loc[:,['Visit Friends & Family', \"Restaurant/Bar/Club\", \"Shopping\", \"Sightseeing\", \"Museum/Art Gallery\", \"Historic site\", \"Zoo/Aquarium\", \"Wildife Viewing/Bird Watching\", \"National/Provincial/Nature Park\"]]\n",
    "\n",
    "# same as above but dependent feature \n",
    "total_spend = df2.loc[:,[\"SPD_DTOT\"]]\n",
    "transport_spend = df2.loc[:,[\"Total Spending for transport\"]]\n",
    "foodbev_spend = df2.loc[:,[\"Total Spending for food/bevs\"]]\n",
    "activities_spend = df2.loc[:,[\"Total spending for activities/entertainment\"]]\n",
    "shopping_spend = df2.loc[:,[\"Total spending on shopping\"]]\n",
    "accomodation_spend = df2.loc[:,[\"SPD_D06\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total spend model\n",
    "#consists of numerical inputs + ori dest new region, transport, transport, quarter, mainreason, high corr activities\n",
    "x_list = [num_features, ori_dest_newregion, transport, quarter, main_reason, high_correlation_activities_cols]\n",
    "# x3_list = [num_features, ori_dest_newregion, transport, quarter, main_reason, all_activities_cols]\n",
    "x_list_transposed = [list_item.transpose() for list_item in x_list]\n",
    "x = pd.concat(x_list_transposed, axis=0).transpose()\n",
    "# dependent variables for each cost model\n",
    "y = total_spend\n",
    "yt = transport_spend\n",
    "yfb = foodbev_spend\n",
    "yat = activities_spend\n",
    "ys = shopping_spend\n",
    "yacc = accomodation_spend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_list = [x, yt]\n",
    "dataframes_list_transposed = [list_item.transpose() for list_item in dataframes_list]\n",
    "merged_dataframe = pd.concat(dataframes_list_transposed, axis=0).transpose()\n",
    "merged_dataframe.dropna(subset=['Total Spending for transport'], inplace=True)\n",
    "merged_dataframe.isnull().any().any()\n",
    "yt = merged_dataframe.loc[:,[\"Total Spending for transport\"]]\n",
    "xt = merged_dataframe.loc[:, merged_dataframe.columns != \"Total Spending for transport\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_list = [x, yfb]\n",
    "dataframes_list_transposed = [list_item.transpose() for list_item in dataframes_list]\n",
    "merged_dataframe = pd.concat(dataframes_list_transposed, axis=0).transpose()\n",
    "merged_dataframe.dropna(subset=['Total Spending for food/bevs'], inplace=True)\n",
    "merged_dataframe.isnull().any().any()\n",
    "yfb = merged_dataframe.loc[:,[\"Total Spending for food/bevs\"]]\n",
    "xfb = merged_dataframe.loc[:, merged_dataframe.columns != \"Total Spending for food/bevs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_list = [x, yat]\n",
    "dataframes_list_transposed = [list_item.transpose() for list_item in dataframes_list]\n",
    "merged_dataframe = pd.concat(dataframes_list_transposed, axis=0).transpose()\n",
    "merged_dataframe.dropna(subset=['Total spending for activities/entertainment'], inplace=True)\n",
    "merged_dataframe.isnull().any().any()\n",
    "yat = merged_dataframe.loc[:,[\"Total spending for activities/entertainment\"]]\n",
    "xat = merged_dataframe.loc[:, merged_dataframe.columns != \"Total spending for activities/entertainment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_list = [x, ys]\n",
    "dataframes_list_transposed = [list_item.transpose() for list_item in dataframes_list]\n",
    "merged_dataframe = pd.concat(dataframes_list_transposed, axis=0).transpose()\n",
    "merged_dataframe.dropna(subset=['Total spending on shopping'], inplace=True)\n",
    "merged_dataframe.isnull().any().any()\n",
    "ys = merged_dataframe.loc[:,[\"Total spending on shopping\"]]\n",
    "xs = merged_dataframe.loc[:, merged_dataframe.columns != \"Total spending on shopping\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_list = [x, yacc]\n",
    "dataframes_list_transposed = [list_item.transpose() for list_item in dataframes_list]\n",
    "merged_dataframe = pd.concat(dataframes_list_transposed, axis=0).transpose()\n",
    "merged_dataframe.dropna(subset=['SPD_D06'], inplace=True)\n",
    "merged_dataframe.isnull().any().any()\n",
    "yacc = merged_dataframe.loc[:,[\"SPD_D06\"]]\n",
    "xacc = merged_dataframe.loc[:, merged_dataframe.columns != \"SPD_D06\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** MODELS BELOW HERE ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "# model = LinearRegression().fit(X_train, y_train)\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "model = LinearRegression().fit(x, y)\n",
    "modelt = LinearRegression().fit(xt, yt)\n",
    "modelfb = LinearRegression().fit(xfb, yfb)\n",
    "modelat = LinearRegression().fit(xat, yat)\n",
    "models = LinearRegression().fit(xs, ys)\n",
    "modelacc = LinearRegression().fit(xacc, yacc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "# model1 = LinearRegression(positive = True, fit_intercept=False).fit(X_train, y_train)\n",
    "\n",
    "# y_pred = model1.predict(X_test)\n",
    "# mse_model = mean_squared_error(y_test, y_pred)\n",
    "# mae_model = mean_absolute_error(y_test, y_pred)\n",
    "# print(f\"Model - MSE: {mse_model} MAE: {mae_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(xt, yt, test_size=0.2, random_state=42)\n",
    "# model1 = LinearRegression(positive = True, fit_intercept=False).fit(X_train, y_train)\n",
    "\n",
    "# y_pred = model1.predict(X_test)\n",
    "# mse_model = mean_squared_error(y_test, y_pred)\n",
    "# mae_model = mean_absolute_error(y_test, y_pred)\n",
    "# print(f\"Model - MSE: {mse_model} MAE: {mae_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(xfb, yfb, test_size=0.2, random_state=42)\n",
    "# model1 = LinearRegression(positive = True, fit_intercept=False).fit(X_train, y_train)\n",
    "\n",
    "# y_pred = model1.predict(X_test)\n",
    "# mse_model = mean_squared_error(y_test, y_pred)\n",
    "# mae_model = mean_absolute_error(y_test, y_pred)\n",
    "# print(f\"Model - MSE: {mse_model} MAE: {mae_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(xat, yat, test_size=0.2, random_state=42)\n",
    "# model1 = LinearRegression(positive = True, fit_intercept=False).fit(X_train, y_train)\n",
    "\n",
    "# y_pred = model1.predict(X_test)\n",
    "# mse_model = mean_squared_error(y_test, y_pred)\n",
    "# mae_model = mean_absolute_error(y_test, y_pred)\n",
    "# print(f\"Model - MSE: {mse_model} MAE: {mae_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(xs, ys, test_size=0.2, random_state=42)\n",
    "# model1 = LinearRegression(positive = True, fit_intercept=False).fit(X_train, y_train)\n",
    "\n",
    "# y_pred = model1.predict(X_test)\n",
    "# mse_model = mean_squared_error(y_test, y_pred)\n",
    "# mae_model = mean_absolute_error(y_test, y_pred)\n",
    "# print(f\"Model - MSE: {mse_model} MAE: {mae_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(xacc, yacc, test_size=0.2, random_state=42)\n",
    "# model1 = LinearRegression(positive = True, fit_intercept=False).fit(X_train, y_train)\n",
    "\n",
    "# y_pred = model1.predict(X_test)\n",
    "# mse_model = mean_squared_error(y_test, y_pred)\n",
    "# mae_model = mean_absolute_error(y_test, y_pred)\n",
    "# print(f\"Model - MSE: {mse_model} MAE: {mae_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model_map = {\n",
    "    \"model\" : model,\n",
    "    \"modelt\" : modelt,\n",
    "    \"modelfb\" : modelfb,\n",
    "    \"modelat\" : modelat,\n",
    "    \"models\" : models,\n",
    "    \"modelacc\" : modelacc\n",
    "}\n",
    "for key, value in model_map.items():\n",
    "    with open(f'../src/{key}.pkl', 'wb') as file:\n",
    "        pickle.dump(value, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
